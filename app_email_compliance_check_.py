# -*- coding: utf-8 -*-
"""App-Email Compliance Check .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12ARJz3jv78zOMdj-OLD0yiDexsFjRpu-
"""

!pip install -q streamlit pyngrok faiss-cpu \
  transformers sentence-transformers \
  langchain langchain-community langchain-huggingface

from pyngrok import ngrok

# Replace with your ngrok token
ngrok.set_auth_token("NGORK TOKEN")

from huggingface_hub import login

#  Replace with your own HF token
login("HF_Token")

from google.colab import drive
drive.mount('/content/drive')

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from langchain.llms import HuggingFacePipeline
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import torch, json, re

class ComplianceAssistant:
    def __init__(self):
        # --- Load embeddings ---
        self.embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

        # --- Load FAISS index ---
        self.faiss_index = FAISS.load_local(
            "/content/drive/MyDrive/FCA_Project/faiss_index",
            embeddings=self.embedding_model,
            allow_dangerous_deserialization=True
        )

        # --- Load LLaMA-3.1 8B Instruct ---
        model_name = "meta-llama/Meta-Llama-3.1-8B-Instruct"
        tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            device_map="auto"
        )

        # HuggingFace pipeline
        gen_pipe = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
            max_new_tokens=512,
            temperature=0.2,
            top_p=0.95
        )

        # LangChain LLM
        llm = HuggingFacePipeline(pipeline=gen_pipe, pipeline_kwargs={"return_full_text": False})

        # Retriever
        retriever = self.faiss_index.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 3, "fetch_k": 15}
        )

        # Custom compliance prompt
        prompt_text = """
You are an FCA compliance assistant.
You will receive FCA Handbook extracts (COBS 4 only) as CONTEXT and an EMAIL.
Your job is to decide if the EMAIL complies with the CONTEXT.

If you are not sure from the CONTEXT, your decision must be "Insufficient context".

Allowed decisions:
- "Compliant"
- "Not Compliant"
- "Insufficient context"

Rules:
- Use ONLY the CONTEXT; do not rely on outside knowledge.
- Cite the specific COBS 4 sections you used (e.g., "COBS 4.2").
- Rewrite the EMAIL only if your decision is "Not Compliant".
- If decision is "Compliant" or "Insufficient context", the "email" field must be "".
- Keep answers short, professional, and JSON only (no explanations outside JSON).

‚ö†Ô∏è Rewriting rules:
- Preserve ALL factual details from the EMAIL (numbers, percentages, dates, names, descriptors like "low-risk").
- Do NOT invent, add, or paraphrase disclaimers, warnings, or risk statements unless the exact wording appears verbatim in CONTEXT.
- If CONTEXT provides mandatory disclaimer wording verbatim, insert it exactly as written (no changes).
- You must NEVER change descriptors (e.g., do not replace "low-risk" with "high-risk").
- You must NEVER keep absolute guarantee terms like "guaranteed", "guarantee", "no risk", "risk-free", or "assured". Replace them with neutral alternatives such as "offers", "may", or "potential". If no compliant rewrite is possible, remove the offending part entirely.
- Only remove or rephrase wording that is misleading or prohibited by the cited COBS 4 section.
- Keep the rewrite as short and as close as possible to the original EMAIL.

‚ö†Ô∏è Strict formatting rule:
Return ONLY ONE JSON object.
Do not provide multiple alternatives.
Do not repeat decisions.

Return your answer strictly in this format:

<JSON>
{{
  "decision": "Compliant" | "Not Compliant" | "Insufficient context",
  "sections": ["COBS 4.x", ...],
  "email": "Rewritten email if decision is 'Not Compliant', otherwise empty string"
}}
</JSON>

CONTEXT:
{context}

EMAIL:
{question}

‚ö†Ô∏è Output ONLY one JSON object. Do not add explanations, labels, or extra text.
Begin directly with <JSON> and end with </JSON>.
"""

        prompt = PromptTemplate(template=prompt_text, input_variables=["context", "question"])

        # RetrievalQA chain
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=retriever,
            chain_type="stuff",
            return_source_documents=True,
            chain_type_kwargs={"prompt": prompt}
        )

    def check_email(self, email_text):
        """Main compliance check (JSON result)."""
        res = self.qa_chain.invoke({"query": email_text})
        matches = re.findall(r"<JSON>(.*?)</JSON>", res["result"], re.DOTALL)

        if not matches:
            return {"decision": "ParseError", "sections": [], "email": ""}

        try:
            parsed = json.loads(matches[0].strip())
            return parsed
        except json.JSONDecodeError:
            return {"decision": "JSONError", "sections": [], "email": ""}

    def save_feedback(self, email, rewrite, feedback):
        with open("feedback.csv", "a", encoding="utf-8") as f:
            f.write(f"\"{email}\",\"{rewrite}\",{feedback}\n")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import json, re, torch
# from langchain_community.vectorstores import FAISS
# from langchain_community.embeddings import HuggingFaceEmbeddings
# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
# from langchain.llms import HuggingFacePipeline
# from langchain.chains import RetrievalQA
# from langchain.prompts import PromptTemplate
# 
# class ComplianceAssistant:
#     def __init__(self):
#         # --- Load embeddings ---
#         self.embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
# 
#         # --- Load FAISS index ---
#         self.faiss_index = FAISS.load_local(
#             "/content/drive/MyDrive/FCA_Project/faiss_index",
#             embeddings=self.embedding_model,
#             allow_dangerous_deserialization=True
#         )
# 
#         # --- Load LLaMA-3.1 8B Instruct ---
#         model_name = "meta-llama/Meta-Llama-3.1-8B-Instruct"
#         tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)
#         model = AutoModelForCausalLM.from_pretrained(
#             model_name,
#             torch_dtype=torch.float16,
#             device_map="auto"
#         )
# 
#         # HuggingFace pipeline
#         gen_pipe = pipeline(
#             "text-generation",
#             model=model,
#             tokenizer=tokenizer,
#             max_new_tokens=512,
#             temperature=0.2,
#             top_p=0.95
#         )
# 
#         # LangChain LLM
#         llm = HuggingFacePipeline(pipeline=gen_pipe, pipeline_kwargs={"return_full_text": False})
# 
#         # Retriever
#         retriever = self.faiss_index.as_retriever(
#             search_type="mmr",
#             search_kwargs={"k": 3, "fetch_k": 15}
#         )
# 
#         # Custom compliance prompt
#         prompt_text = """
# You are an FCA compliance assistant.
# You will receive FCA Handbook extracts (COBS 4 only) as CONTEXT and an EMAIL.
# Your job is to decide if the EMAIL complies with the CONTEXT.
# 
# If you are not sure from the CONTEXT, your decision must be "Insufficient context".
# 
# Allowed decisions:
# - "Compliant"
# - "Not Compliant"
# - "Insufficient context"
# 
# Rules:
# - Use ONLY the CONTEXT; do not rely on outside knowledge.
# - Cite the specific COBS 4 sections you used (e.g., "COBS 4.2").
# - Rewrite the EMAIL only if your decision is "Not Compliant".
# - If decision is "Compliant" or "Insufficient context", the "email" field must be "".
# - Keep answers short, professional, and JSON only (no explanations outside JSON).
# 
# ‚ö†Ô∏è Rewriting rules:
# - Preserve ALL factual details from the EMAIL (numbers, percentages, dates, names, descriptors like "low-risk").
# - Do NOT invent, add, or paraphrase disclaimers, warnings, or risk statements unless the exact wording appears verbatim in CONTEXT.
# - If CONTEXT provides mandatory disclaimer wording verbatim, insert it exactly as written (no changes).
# - You must NEVER change descriptors (e.g., do not replace "low-risk" with "high-risk").
# - You must NEVER keep absolute guarantee terms like "guaranteed", "guarantee", "no risk", "risk-free", or "assured". Replace them with neutral alternatives such as "offers", "may", or "potential". If no compliant rewrite is possible, remove the offending part entirely.
# - Only remove or rephrase wording that is misleading or prohibited by the cited COBS 4 section.
# - Keep the rewrite as short and as close as possible to the original EMAIL.
# 
# ‚ö†Ô∏è Strict formatting rule:
# Return ONLY ONE JSON object.
# Do not provide multiple alternatives.
# Do not repeat decisions.
# 
# Return your answer strictly in this format:
# 
# <JSON>
# {{
#   "decision": "Compliant" | "Not Compliant" | "Insufficient context",
#   "sections": ["COBS 4.x", ...],
#   "email": "Rewritten email if decision is 'Not Compliant', otherwise empty string"
# }}
# </JSON>
# 
# CONTEXT:
# {context}
# 
# EMAIL:
# {question}
# 
# ‚ö†Ô∏è Output ONLY one JSON object. Do not add explanations, labels, or extra text.
# Begin directly with <JSON> and end with </JSON>.
# """
# 
#         prompt = PromptTemplate(template=prompt_text, input_variables=["context", "question"])
# 
#         # RetrievalQA chain
#         self.qa_chain = RetrievalQA.from_chain_type(
#             llm=llm,
#             retriever=retriever,
#             chain_type="stuff",
#             return_source_documents=True,
#             chain_type_kwargs={"prompt": prompt}
#         )
# 
#     def check_email(self, email_text):
#         """Main compliance check (JSON result)."""
#         res = self.qa_chain.invoke({"query": email_text})
#         matches = re.findall(r"<JSON>(.*?)</JSON>", res["result"], re.DOTALL)
# 
#         if not matches:
#             return {"decision": "ParseError", "sections": [], "email": ""}
# 
#         try:
#             parsed = json.loads(matches[0].strip())
#             return parsed
#         except json.JSONDecodeError:
#             return {"decision": "JSONError", "sections": [], "email": ""}
# 
#     def save_feedback(self, email, rewrite, feedback):
#         with open("feedback.csv", "a", encoding="utf-8") as f:
#             f.write(f"\"{email}\",\"{rewrite}\",{feedback}\n")
# 
# 
# st.set_page_config(page_title="Compliance Assistant", layout="wide")
# st.title("üìß FCA Compliance Assistant")
# st.write("Check and rewrite client emails for FCA COBS 4 compliance.")
# 
# email_text = st.text_area("‚úçÔ∏è Paste your email draft here:", height=200)
# 
# if st.button("Run Compliance Check"):
#     st.info("üöÄ Button clicked")  # Debug marker
# 
#     if email_text.strip():
#         assistant = ComplianceAssistant()
# 
#         try:
#             with st.spinner("üîÑ Running compliance check... please wait"):
#                 result = assistant.check_email(email_text)
# 
#             st.success("‚úÖ Backend finished running!")  # Confirm it finished
# 
#             # Show raw model output
#             if "raw" in result:
#                 st.subheader("üìù Raw Model Output")
#                 st.code(result["raw"])
# 
#             # Show parsed JSON
#             st.subheader("üîé Decision")
#             st.write(result.get("decision", "Unknown"))
# 
#             st.subheader("üìë Sections")
#             st.write(", ".join(result.get("sections", [])))
# 
#             st.subheader("‚úÖ Rewrite")
#             if result.get("email"):
#                 st.success(result["email"])
#             else:
#                 st.info("No rewrite needed.")
# 
#         except Exception as e:
#             st.error(f"‚ùå Backend error: {e}")
# 
#     else:
#         st.warning("Please paste an email draft first.")

import subprocess
from pyngrok import ngrok

# Kill any existing tunnels
ngrok.kill()

# Start a new tunnel on port 8501
port = 8501
public_url = ngrok.connect(port)
print("üåç Streamlit app is live at:", public_url)

# Launch Streamlit in background
subprocess.Popen(["streamlit", "run", "app.py", "--server.port", str(port)])